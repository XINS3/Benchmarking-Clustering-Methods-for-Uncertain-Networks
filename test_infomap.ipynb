{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Figure 11: Expected modularity according to the different community strengths\n",
    "## Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "from Expected_mod import Trans_C1\n",
    "from infomap import Infomap\n",
    "import Expected_mod as ex\n",
    "path='mcp_acp_data//k10_l10//'\n",
    "filelist=[i for i in os.listdir(path) if (i[-3:]=='txt' and i[10]=='1' and i[11]=='0' and i[12]=='_' )]\n",
    "filelist.sort()\n",
    "filelist\n",
    "\n",
    "# run weighted louvain, save clustering\n",
    "k=10\n",
    "l=10\n",
    "value=[]\n",
    "T=[]\n",
    "clustering=[]\n",
    "#path='datasets//'\n",
    "\n",
    "for graph in filelist:\n",
    "    im=Infomap()\n",
    "    im.read_file(path+graph)\n",
    "    im.run()\n",
    "    #g=load_graph.read_g(path+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for link in im.get_links(data='weight'):\n",
    "        edge.append((link[0],link[1]))\n",
    "        p.append(link[2])\n",
    "    t1=time.time()\n",
    "    cluster=im.getModules(states=True)\n",
    "\n",
    "    cluster=[i for i in cluster.values()]\n",
    "    t2=time.time()\n",
    "    print('******',graph)\n",
    "    print(graph,'--','cluster:',cluster)\n",
    "    # repeat three times\n",
    "    clustering.append(cluster)\n",
    "\n",
    "    Emod=ex.APWP(edge,p,Trans_C1(cluster))\n",
    "    \n",
    "\n",
    "    print('----------graph: ',graph,'----------')\n",
    "    #print('cluster:',cluster)\n",
    "    print('Ex modularity',Emod)\n",
    "    value.append(Emod)\n",
    "    T.append(t2-t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according to Figure 12: AMI score according to the community strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami \n",
    "node=100\n",
    "nomalized_cluster=Trans_C2(Trans_C1(clustering[0]),node)\n",
    "\n",
    "print('n',nomalized_cluster)\n",
    "AMI=[]\n",
    "for c in clustering:\n",
    "    c=Trans_C2(Trans_C1(c),node)\n",
    "    \n",
    "    score=ami(nomalized_cluster,list(c))\n",
    "    \n",
    "    AMI.append(float(score))\n",
    "print(AMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according toFigure 13: AMI score according to the increasing number of clusters, community strength s = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami \n",
    "\n",
    "importlib.reload(load_graph)\n",
    "path2='mcp_acp_data//l10_p0.3//datasets//'\n",
    "\n",
    "filelist1=[i for i in os.listdir(path2) if i[-3:]=='txt'  ]\n",
    "filelist1.sort()\n",
    "print(filelist1)\n",
    "\n",
    "NMI=[]\n",
    "X_=[]\n",
    "l=10\n",
    "path='mcp_acp_data//l10_p0.3//datasets//'\n",
    "for graph in filelist1:\n",
    "   \n",
    "    im=Infomap()\n",
    "    im.read_file(path+graph)\n",
    "    im.run()\n",
    "    cluster=im.getModules(states=True)\n",
    "\n",
    "    cluster=[i for i in cluster.values()]\n",
    "    \n",
    "    strr=[]\n",
    "    flag=0\n",
    "   \n",
    "    for _ in graph:\n",
    "        if _=='k':\n",
    "            \n",
    "            flag=1\n",
    "            continue\n",
    "        if flag==0:\n",
    "            continue\n",
    "        if _<'0' or _>'9':\n",
    "           \n",
    "            break\n",
    "        strr.append(_)\n",
    "    \n",
    "    k=sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "    c=[i for i in range(k*l)]\n",
    "    \n",
    "    stad_cluster=[c[x:x+l] for x in range(0, len(c), l)]\n",
    "    nmi_=ami(Trans_C2(stad_cluster,k*l),cluster)\n",
    "    NMI.append(nmi_)\n",
    "    X_.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to low prob. according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "    \n",
    "path2='datasets//l10_p0.3_evolving_lowP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "\n",
    "# run weighted louvain, save clustering\n",
    "\n",
    "Info={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "\n",
    "        im=Infomap()\n",
    "        im.read_file(path2+file)\n",
    "        im.run()\n",
    "        cluster=im.getModules(states=True)\n",
    "\n",
    "        cluster=[i for i in cluster.values()]\n",
    "        cluster=Trans_C1(cluster)\n",
    "       \n",
    "        Info.update({k:cluster})\n",
    "\n",
    "\n",
    "\n",
    "# run ex mod, save time and value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_lowP1//result//Infomap//'\n",
    "with open(path+'infomap_increaseK_lowP.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'infomap_increaseK_lowP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment of high prob. according to Performances under Different Probability Distribu- tions (RQ5)\n",
    "\n",
    "## have completely same graph structures with low prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "    \n",
    "path2='datasets//l10_p0.3_evolving_highP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "\n",
    "# run weighted louvain, save clustering\n",
    "\n",
    "Info={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "\n",
    "        im=Infomap()\n",
    "        im.read_file(path2+file)\n",
    "        im.run()\n",
    "        cluster=im.getModules(states=True)\n",
    "\n",
    "        cluster=[i for i in cluster.values()]\n",
    "        cluster=Trans_C1(cluster)\n",
    "       \n",
    "        Info.update({k:cluster})\n",
    "\n",
    "\n",
    "\n",
    "# run ex mod, save time and value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_highP1//result//Infomap//'\n",
    "with open(path+'infomap_increaseK_highP.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment polarized graph according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "    \n",
    "path2='datasets//l50_k2_p0.18_polarized_graph//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "\n",
    "# run weighted louvain, save clustering\n",
    "\n",
    "Info={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "        name=file_list[-2]\n",
    "\n",
    "        im=Infomap()\n",
    "        im.read_file(path2+file)\n",
    "        im.run()\n",
    "        cluster=im.getModules(states=True)\n",
    "\n",
    "        cluster=[i for i in cluster.values()]\n",
    "        cluster=Trans_C1(cluster)\n",
    "       \n",
    "        Info.update({name:cluster})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l50_k2_p0.18_polarized_graph//result//Infomap//'\n",
    "with open(path+'infomap_polarized.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_core & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "\n",
    "Info={}\n",
    "    \n",
    "path2='mcp_acp_data//krogan2006_core//intersec_mips//net//krogan2006_core_mips_net.txt'\n",
    "im=Infomap()\n",
    "im.read_file(path2)\n",
    "im.run()\n",
    "cluster=im.getModules(states=True)\n",
    "k=len(cluster)\n",
    "\n",
    "cluster=[i for i in cluster.values()]\n",
    "cluster=Trans_C1(cluster)\n",
    "\n",
    "Info.update({k:cluster})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//krogan2006_core//intersec_mips//Infomap_results//'\n",
    "with open(path+'infomap.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_extended & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "\n",
    "Info={}\n",
    "    \n",
    "path2='mcp_acp_data//krogan2006_extended//intersec_mips//krogan2006_extented_mips_net.txt'\n",
    "im=Infomap()\n",
    "im.read_file(path2)\n",
    "im.run()\n",
    "cluster=im.getModules(states=True)\n",
    "k=len(cluster)\n",
    "\n",
    "cluster=[i for i in cluster.values()]\n",
    "cluster=Trans_C1(cluster)\n",
    "\n",
    "Info.update({k:cluster})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//krogan2006_extended//intersec_mips//Infomap_results//'\n",
    "with open(path+'infomap.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Shifting Probabilities (RQ2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "    \n",
    "path2='mcp_acp_data//l10_k10_p0.4_multiplied//new//datasets//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "print(filelists)\n",
    "# run weighted louvain, save clustering\n",
    "\n",
    "Info={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "        strr=[]\n",
    "        flag=0\n",
    "    \n",
    "        for _ in file:\n",
    "            if _=='i':\n",
    "                \n",
    "                flag=1\n",
    "                continue\n",
    "            if flag==0:\n",
    "                continue\n",
    "            if _<'0' or _>'9':\n",
    "            \n",
    "                break\n",
    "            strr.append(_)\n",
    "\n",
    "        multi=str(0)+'.'+str(strr[1])#sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "        print(file)\n",
    "        print('m',multi)\n",
    "        \n",
    "        im=Infomap()\n",
    "        im.read_file(path2+file)\n",
    "        im.run()\n",
    "        cluster=im.getModules(states=True)\n",
    "\n",
    "        cluster=[i for i in cluster.values()]\n",
    "        cluster=Trans_C1(cluster)\n",
    "       \n",
    "        Info.update({multi:cluster})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_k10_p0.4_multiplied//new//Infomap_results//'\n",
    "with open(path+'infomap.json','w') as fp:\n",
    "          json.dump(Info,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'infomap.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
