{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pKwikCluster as pkwik \n",
    "import load_graph\n",
    "import importlib\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import Expected_mod as ex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Figure 11: Expected modularity according to the different community strengths\n",
    "## pKwikcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected modularity\n",
    "\n",
    "\n",
    "from Expected_mod import Trans_C2,APWP\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "import pKwikCluster\n",
    "import load_graph\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami\n",
    "path='mcp_acp_data//k10_l10//'\n",
    "filelist=[i for i in os.listdir(path) if (i[-3:]=='txt' and i[10]=='1' and i[11]=='0' and i[12]=='_' )]\n",
    "filelist.sort()\n",
    "g=load_graph.read_g(path+'evolving_k10_l10_p0.00.txt')\n",
    "c=nx.community.louvain_communities(g)\n",
    "node=100\n",
    "nomalized_cluster=Trans_C2(c,node)\n",
    "print(nomalized_cluster)\n",
    "AMI=[]\n",
    "#path='datasets//'\n",
    "\n",
    "for graph in filelist:\n",
    "    rep=5\n",
    "    current_exp=0\n",
    "    for _ in range(rep):\n",
    "        \n",
    "        g=load_graph.read_g(path+graph)\n",
    "        edge=[]\n",
    "        p=[]\n",
    "        for u,v,w in g.edges(data=True):\n",
    "            edge.append((u,v))\n",
    "            p.append(w['weight'])\n",
    "    \n",
    "\n",
    "        # repeat three times\n",
    "    \n",
    "        \n",
    "        \n",
    "       \n",
    "        cluster=pKwikCluster.pKwikCluster(g)\n",
    "        \n",
    "        #clustering.append(cluster)\n",
    "       # nmi_=nmi(nomalized_cluster,Trans_C2(cluster,node))\n",
    "        \n",
    "        current_exp+=APWP(edge,p,cluster)\n",
    "        print(current_exp)\n",
    "\n",
    "    print('----------graph: ',graph,'----------')\n",
    "    #print('cluster:',cluster)\n",
    "    print('nmi',current_exp/rep)\n",
    "    \n",
    "    AMI.append(current_exp/rep)\n",
    "print(AMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according to Figure 12: AMI score according to the community strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C2\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "import pKwikCluster\n",
    "import load_graph\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami\n",
    "path='mcp_acp_data//k10_l10//'\n",
    "filelist=[i for i in os.listdir(path) if (i[-3:]=='txt' and i[10]=='1' and i[11]=='0' and i[12]=='_' )]\n",
    "filelist.sort()\n",
    "g=load_graph.read_g(path+'evolving_k10_l10_p0.00.txt')\n",
    "c=nx.community.louvain_communities(g)\n",
    "node=100\n",
    "nomalized_cluster=Trans_C2(c,node)\n",
    "print(nomalized_cluster)\n",
    "AMI=[]\n",
    "#path='datasets//'\n",
    "\n",
    "for graph in filelist:\n",
    "    rep=5\n",
    "    current_ami=0\n",
    "    for _ in range(rep):\n",
    "        \n",
    "        g=load_graph.read_g(path+graph)\n",
    "   \n",
    "        cluster=pKwikCluster.pKwikCluster(g)\n",
    "   \n",
    "        current_ami+=ami(nomalized_cluster,Trans_C2(cluster,node))\n",
    "        print(current_ami)\n",
    "\n",
    "    print('----------graph: ',graph,'----------')\n",
    "    #print('cluster:',cluster)\n",
    "    print('nmi',current_ami/rep)\n",
    "    \n",
    "    AMI.append(current_ami/rep)\n",
    "print(AMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according toFigure 13: AMI score according to the increasing number of clusters, community strength s = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami \n",
    "\n",
    "path2='mcp_acp_data//l10_p0.3//datasets//'\n",
    "\n",
    "filelist1=[i for i in os.listdir(path2) if i[-3:]=='txt'  ]\n",
    "filelist1.sort()\n",
    "print(filelist1)\n",
    "\n",
    "NMI=[]\n",
    "X_=[]\n",
    "l=10\n",
    "path='mcp_acp_data//l10_p0.3//datasets//'\n",
    "for graph in filelist1:\n",
    "    print(graph)\n",
    "    g=load_graph.read_g(path+graph)\n",
    "   \n",
    "    # cut str\n",
    "    strr=[]\n",
    "    flag=0\n",
    "   \n",
    "    for _ in graph:\n",
    "        if _=='k':\n",
    "            \n",
    "            flag=1\n",
    "            continue\n",
    "        if flag==0:\n",
    "            continue\n",
    "        if _<'0' or _>'9':\n",
    "           \n",
    "            break\n",
    "        strr.append(_)\n",
    "    \n",
    "    k=sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "    c=[i for i in range(k*l)]\n",
    "    \n",
    "    stad_cluster=[c[x:x+l] for x in range(0, len(c), l)]\n",
    "    stad_cluster2=Trans_C2(stad_cluster,k*l)\n",
    " \n",
    "    # repeat three times\n",
    "   \n",
    "    current_nmi=0\n",
    "    time=3\n",
    "    clu3=[]\n",
    "    for _ in range(time):\n",
    "        g=load_graph.read_g(path+graph)\n",
    "        cluster=pkwik.pKwikCluster(g)\n",
    "        \n",
    "        cluster2=Trans_C2(cluster,k*l)\n",
    "      \n",
    "        nmi_=ami(stad_cluster2,cluster2)\n",
    "     \n",
    "        print(nmi_)\n",
    "        \n",
    "        current_nmi+=nmi_\n",
    "        \n",
    "    print('----------graph: ',graph,'----------')\n",
    "\n",
    "    print('nmi',current_nmi/time)\n",
    "\n",
    "    NMI.append(current_nmi/time)\n",
    "    X_.append(k)\n",
    "print(NMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to low prob. according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "\n",
    "path2='datasets//l10_p0.3_evolving_lowP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "pwik={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=pkwik.pKwikCluster(g)\n",
    "        \n",
    "        \n",
    "        pwik.update({k:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_lowP1//result//pkwik//'\n",
    "with open(path+'pkwik_increaseK_lowP.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'pkwik_increaseK_lowP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment of high prob. according to Performances under Different Probability Distribu- tions (RQ5)\n",
    "\n",
    "## have completely same graph structures with low prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "\n",
    "path2='datasets//l10_p0.3_evolving_highP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "pwik={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=pkwik.pKwikCluster(g)\n",
    "        \n",
    "        \n",
    "        pwik.update({k:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_lowP1//result//pkwik//'\n",
    "with open(path+'pkwik_increaseK_highP.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)pkwik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'pkwik_increaseK_highP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment polarized graph according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "\n",
    "path2='datasets//l50_k2_p0.18_polarized_graph//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "pwik={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        name=file_list[-2]\n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    "        cluster=pkwik.pKwikCluster(g)\n",
    "        \n",
    "        \n",
    "        pwik.update({name:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l50_k2_p0.18_polarized_graph//result//pkwik//'\n",
    "with open(path+'pkwik_polarized.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)pkwik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_core & mips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # krogan2006_core\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "\n",
    "pwik={}\n",
    "    \n",
    "path2='mcp_acp_data//krogan2006_core//intersec_mips//net//krogan2006_core_mips_net.txt'\n",
    "g=load_graph.read_g(path2)\n",
    "cluster=pkwik.pKwikCluster(g)\n",
    "k=len(cluster)\n",
    "        \n",
    "pwik.update({k:cluster})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//krogan2006_core//intersec_mips//pwik_results//'\n",
    "with open(path+'pwik10.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_extende & mips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # krogan2006_core\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import clustering_bayesian_ref\n",
    "importlib.reload(clustering_bayesian_ref)\n",
    "import clustering_bayesian_ref as br \n",
    "import load_graph\n",
    "from Expected_mod import Trans_C1\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import networkx\n",
    "from infomap import Infomap\n",
    "\n",
    "pwik={}\n",
    "    \n",
    "path2='mcp_acp_data//krogan2006_extended//intersec_mips//krogan2006_extented_mips_net.txt'\n",
    "g=load_graph.read_g(path2)\n",
    "cluster=pkwik.pKwikCluster(g)\n",
    "k=len(cluster)\n",
    "        \n",
    "pwik.update({k:cluster})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//krogan2006_extended//intersec_mips//pwik_results//'\n",
    "with open(path+'pwik.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Shifting Probabilities (RQ2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "\n",
    "path2='mcp_acp_data//l10_k10_p0.4_multiplied//new//datasets//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "pwik={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        strr=[]\n",
    "        flag=0\n",
    "    \n",
    "        for _ in file:\n",
    "            if _=='i':\n",
    "                \n",
    "                flag=1\n",
    "                continue\n",
    "            if flag==0:\n",
    "                continue\n",
    "            if _<'0' or _>'9':\n",
    "            \n",
    "                break\n",
    "            strr.append(_)\n",
    "    \n",
    "        multi=str(0)+'.'+str(strr[1])#sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "        print(multi)\n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "  \n",
    "        cluster=pkwik.pKwikCluster(g)\n",
    "        \n",
    "        \n",
    "        pwik.update({multi:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l10_k10_p0.4_multiplied//new//pwik_results//'\n",
    "with open(path+'pwik.json','w') as fp:\n",
    "          json.dump(pwik,fp,indent=4) # With indent=4 (pretty format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
