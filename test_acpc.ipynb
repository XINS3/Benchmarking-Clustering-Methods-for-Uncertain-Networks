{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Figure 11: Expected modularity according to the different community strengths\n",
    "## ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import bz2\n",
    "import os \n",
    "import pandas as pd \n",
    "import json\n",
    "import time\n",
    "import networkx as nx \n",
    "importlib.reload(load_graph)\n",
    "path='mcp_acp_data//k10_l10//result//acpc//'\n",
    "path2='datasets//'\n",
    "filelists=[i for i in os.listdir('mcp_acp_data//k10_l10//result//acpc')]\n",
    "filelists.sort()\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "for file in filelists:\n",
    "    print(file)\n",
    "    graph=file[:-9]+'.txt'\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "    with bz2.open(path+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    " \n",
    "    print(Trans_C1(list(clustering_df['clabel'])),len(Trans_C1(list(clustering_df['clabel']))))\n",
    "    print(list(clustering_df['probability']))\n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    clustering.append(cluster)\n",
    "    Emod=ex.APWP(edge,p,cluster)\n",
    "    print('----------graph: ',graph,'----------')\n",
    "    print('cluster:',cluster)\n",
    "    print('-----------Ex modularity',Emod,'-----------')\n",
    "    value.append(Emod)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according to Figure 12: AMI score according to the community strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami\n",
    "\n",
    "standard_c=[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
    "node=100\n",
    "AMI=[]\n",
    "for c in clustering:\n",
    "    c=Trans_C2(c,node)\n",
    "    \n",
    "    score=ami(standard_c,c)\n",
    "    print(score)\n",
    "    AMI.append(score)\n",
    "print(AMI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according toFigure 13: AMI score according to the increasing number of clusters, community strength s = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami \n",
    "\n",
    "importlib.reload(load_graph)\n",
    "path='mcp_acp_data//l10_p0.3//results//acpc_results//'\n",
    "path2='mcp_acp_data//l10_p0.3//datasets//'\n",
    "filelists=[i for i in os.listdir('mcp_acp_data//l10_p0.3//results//acpc_results//')]\n",
    "filelists.sort()\n",
    "print(filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "X_=[]\n",
    "l=10\n",
    "NMI=[]\n",
    "for file in filelists:\n",
    "    print(file)\n",
    "    graph=file[:-9]+'.txt'\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "   \n",
    "\n",
    "    with bz2.open(path+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "\n",
    "    print(Trans_C1(list(clustering_df['clabel'])),len(Trans_C1(list(clustering_df['clabel']))))\n",
    "    print(list(clustering_df['probability']))\n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    strr=[]\n",
    "    flag=0\n",
    "   \n",
    "    for _ in graph:\n",
    "        if _=='k':\n",
    "            \n",
    "            flag=1\n",
    "            continue\n",
    "        if flag==0:\n",
    "            continue\n",
    "        if _<'0' or _>'9':\n",
    "           \n",
    "            break\n",
    "        strr.append(_)\n",
    "    \n",
    "    k=sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "    c=[i for i in range(k*l)]\n",
    "    \n",
    "    stad_cluster=[c[x:x+l] for x in range(0, len(c), l)]\n",
    "    nmi_=ami(Trans_C2(stad_cluster,k*l),Trans_C2(cluster,k*l))\n",
    "    NMI.append(nmi_)\n",
    "    X_.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to low prob. according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//l10_p0.3_evolving_lowP1//result//acpc//'\n",
    "path2='mcp_acp_data//l10_p0.3_evolving_lowP1//'\n",
    "filelists=[i for i in os.listdir(path1)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "for file in filelists:\n",
    "   \n",
    "    file_list=file.split('_')\n",
    "    k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "    \n",
    "    graph=file[:-9]+'.txt'\n",
    "    print('file',file)\n",
    "    print(graph)\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "    with bz2.open(path1+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "   \n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    acpc_clustering.update({k:cluster})\n",
    "    print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_lowP1//result//acpc//'\n",
    "with open(path+'acpc_increaseK_lowP.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'acpc_increaseK_lowP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment of high prob. according to Performances under Different Probability Distribu- tions (RQ5)\n",
    "\n",
    "## have completely same graph structures with low prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//l10_p0.3_evolving_highP1//result//acpc//'\n",
    "path2='mcp_acp_data//l10_p0.3_evolving_highP1//'\n",
    "filelists=[i for i in os.listdir(path1)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "for file in filelists:\n",
    "   \n",
    "    file_list=file.split('_')\n",
    "    k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "    \n",
    "    graph=file[:-9]+'.txt'\n",
    "    print('file',file)\n",
    "    print(graph)\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "    with bz2.open(path1+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "   \n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    acpc_clustering.update({k:cluster})\n",
    "    print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_highP1//result//acpc//'\n",
    "with open(path+'acpc_increaseK_highP.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'acpc_increaseK_highP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment polarized graph according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//l50_k2_p0.18_polarized_graph//result//acpc//'\n",
    "path2='mcp_acp_data//l50_k2_p0.18_polarized_graph//'\n",
    "filelists=[i for i in os.listdir(path1) if i !='.DS_Store']\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "for file in filelists:\n",
    "    print(file)\n",
    "    file_list=file.split('_')\n",
    "    k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "    name=file_list[-2]\n",
    "    \n",
    "    graph=file[:-9]+'.txt'\n",
    "    print('file',file)\n",
    "    print(graph)\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "    with bz2.open(path1+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "    \n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    acpc_clustering.update({name:cluster})\n",
    "    print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l50_k2_p0.18_polarized_graph//result//acpc//'\n",
    "with open(path+'acpc_polarized.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## krogan2006 core & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//krogan2006_core//intersec_mips//acpc_results//'\n",
    "path2='mcp_acp_data//krogan2006_core//intersec_mips/net//krogan2006_core_mips_net.txt'\n",
    "\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "\n",
    "\n",
    "g=load_graph.read_g(path2)\n",
    "file1='krogan2006_core_mips_net.json.bz2'\n",
    "\n",
    "with bz2.open(path1+file1,'rt') as f:\n",
    "    data=json.load(f)\n",
    "# convert the table to dataframe\n",
    "clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "\n",
    "cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "k=len(cluster)\n",
    "acpc_clustering.update({k:cluster})\n",
    "print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n",
    "   # T.append(t2-t1)\n",
    "    #print(clustering_df.to_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//krogan2006_core//intersec_mips//acpc_results//'\n",
    "with open(path+'acpc_k188.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## krogan2006 extended & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//krogan2006_extended//intersec_mips//acpc_results//'\n",
    "path2='mcp_acp_data//krogan2006_extended//intersec_mips//krogan2006_extented_mips_net.txt'\n",
    "\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "\n",
    "\n",
    "g=load_graph.read_g(path2)\n",
    "file1='krogan2006_extented_mips_net.json.bz2'\n",
    "\n",
    "with bz2.open(path1+file1,'rt') as f:\n",
    "    data=json.load(f)\n",
    "# convert the table to dataframe\n",
    "clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "\n",
    "cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "k=len(cluster)\n",
    "print(cluster)\n",
    "acpc_clustering.update({k:cluster})\n",
    "print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n",
    "   # T.append(t2-t1)\n",
    "    #print(clustering_df.to_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//krogan2006_extended//intersec_mips//acpc_results//'\n",
    "with open(path+'acpc_k195.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Shifting Probabilities (RQ2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1, APWP\n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "importlib.reload(load_graph)\n",
    "acpc_clustering={}\n",
    "path1='mcp_acp_data//l10_k10_p0.4_multiplied//new//acp_results//'\n",
    "path2='mcp_acp_data//l10_k10_p0.4_multiplied//new//datasets//'\n",
    "filelists=[i for i in os.listdir(path1) if i !='.DS_Store']\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "print(filelists)\n",
    "for file in filelists:\n",
    "    print(file)\n",
    "    file_list=file.split('_')\n",
    "    strr=[]\n",
    "    flag=0\n",
    "   \n",
    "    for _ in file:\n",
    "        if _=='i':\n",
    "            \n",
    "            flag=1\n",
    "            continue\n",
    "        if flag==0:\n",
    "            continue\n",
    "        if _<'0' or _>'9':\n",
    "           \n",
    "            break\n",
    "        strr.append(_)\n",
    "    print(strr)\n",
    "    multi=str(0)+'.'+str(strr[1])#sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "    print(multi)\n",
    " \n",
    "    \n",
    "    graph=file[:-9]+'.txt'\n",
    "    \n",
    "    print('g',graph)\n",
    "    g=load_graph.read_g(path2+graph)\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "    with bz2.open(path1+file,'rt') as f:\n",
    "        data=json.load(f)\n",
    "    # convert the table to dataframe\n",
    "    clustering_df=pd.DataFrame(data['tables']['clustering'])\n",
    "\n",
    "\n",
    "    cluster=Trans_C1(list(clustering_df['clabel']))\n",
    "    acpc_clustering.update({multi:cluster})\n",
    "    print(cluster)\n",
    "   \n",
    "print(acpc_clustering)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "path='mcp_acp_data//l10_k10_p0.4_multiplied//new//acp_results//'\n",
    "with open(path+'acpc.json','w') as fp:\n",
    "          json.dump(acpc_clustering,fp,indent=4) # With indent=4 (pretty format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
