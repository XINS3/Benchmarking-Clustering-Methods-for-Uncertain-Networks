{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_graph\n",
    "import importlib\n",
    "importlib.reload(load_graph)\n",
    "import load_graph\n",
    "import Expected_mod as ex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# According to Figure 11: Expected modularity according to the different community strengths\n",
    "## louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dic choose file automatically\n",
    "\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "path='mcp_acp_data//k10_l10//'\n",
    "filelist=[i for i in os.listdir(path) if (i[-3:]=='txt' and i[10]=='1' and i[11]=='0' and i[12]=='_' )]\n",
    "filelist.sort()\n",
    "filelist\n",
    "\n",
    "# run weighted louvain, save clustering\n",
    "k=10\n",
    "l=10\n",
    "value=[]\n",
    "T=[]\n",
    "clustering=[]\n",
    "#path='datasets//'\n",
    "for graph in filelist:\n",
    "    g=load_graph.read_g(path+graph)\n",
    "\n",
    "\n",
    "    edge=[]\n",
    "    p=[]\n",
    "    for u,v,w in g.edges(data=True):\n",
    "        edge.append((u,v))\n",
    "        p.append(w['weight'])\n",
    "\n",
    "\n",
    "    t1=time.time()\n",
    "    cluster=nx.community.louvain_communities(g)\n",
    "    t2=time.time()\n",
    "\n",
    "\n",
    "    clustering.append(cluster)\n",
    "    Emod=ex.APWP(edge,p,cluster)\n",
    "    print('----------graph: ',graph,'----------')\n",
    "    print('cluster:',cluster)\n",
    "    print('-----------Ex modularity',Emod,'-----------')\n",
    "    value.append(Emod)\n",
    "    T.append(t2-t1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according to Figure 12: AMI score according to the community strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami\n",
    "print(clustering)\n",
    "node=100\n",
    "nomalized_cluster=Trans_C2(clustering[0],node)\n",
    "print(nomalized_cluster)\n",
    "AMI=[]\n",
    "for c in clustering:\n",
    "    c=Trans_C2(c,node)\n",
    "    \n",
    "    score=ami(nomalized_cluster,c)\n",
    "    print(score)\n",
    "    AMI.append(score)\n",
    "print(AMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate AMI according toFigure 13: AMI score according to the increasing number of clusters, community strength s = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Expected_mod import Trans_C1\n",
    "from Expected_mod import Trans_C2\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score as ami \n",
    "\n",
    "def sum(l):\n",
    "    s=0\n",
    "    for i in l:\n",
    "        s+=i\n",
    "\n",
    "    return  s\n",
    "\n",
    "path2='mcp_acp_data//l10_p0.3//datasets//'\n",
    "filelist1=[i for i in os.listdir(path2) if i[-3:]=='txt'  ]\n",
    "filelist1.sort()\n",
    "print(filelist1)\n",
    "\n",
    "NMI1=[]\n",
    "X_=[]\n",
    "l=10\n",
    "path='mcp_acp_data//l10_p0.3//datasets//'\n",
    "for graph in filelist1:\n",
    "    \n",
    "    g=load_graph.read_g(path+graph)\n",
    "    cluster1=nx.community.louvain_communities(g)\n",
    "    \n",
    "    # cut str\n",
    "    strr=[]\n",
    "    flag=0\n",
    "   \n",
    "    for _ in graph:\n",
    "        if _=='k':\n",
    "            \n",
    "            flag=1\n",
    "            continue\n",
    "        if flag==0:\n",
    "            continue\n",
    "        if _<'0' or _>'9':\n",
    "           \n",
    "            break\n",
    "        strr.append(_)\n",
    "    \n",
    "    k=sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "    c=[i for i in range(k*l)]\n",
    "    \n",
    "    stad_cluster=[c[x:x+l] for x in range(0, len(c), l)]\n",
    "    \n",
    " \n",
    "   \n",
    "    cluster1=Trans_C2(cluster1,k*l)\n",
    "\n",
    "    #print(Trans_C2(stad_cluster,k*l),cluster1)\n",
    "    nmi_=ami(Trans_C2(stad_cluster,k*l),cluster1)\n",
    "    print(nmi_)\n",
    "    NMI1.append(nmi_)\n",
    "    X_.append(k)\n",
    "    print('k:',k,'nmi',nmi_)\n",
    "  \n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to low prob. according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='datasets//l10_p0.3_evolving_lowP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "        \n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=nx.community.louvain_communities(g)\n",
    "        \n",
    "        cluster=Trans_C2(cluster,int(k)*int(l))\n",
    "        cluster=Trans_C1(cluster)\n",
    "        \n",
    "        \n",
    "        louvain.update({k:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_lowP1//result//weigted_louvain//'\n",
    "with open(path+'louvain_increaseK_lowP.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'louvain_increaseK_lowP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment of high prob. according to Performances under Different Probability Distribu- tions (RQ5)\n",
    "\n",
    "## have completely same graph structures with low prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='datasets//l10_p0.3_evolving_highP1//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "        \n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=nx.community.louvain_communities(g)\n",
    "        \n",
    "        cluster=Trans_C2(cluster,int(k)*int(l))\n",
    "        cluster=Trans_C1(cluster)\n",
    "        \n",
    "        \n",
    "        louvain.update({k:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_p0.3_evolving_highP1//result//weigted_louvain//'\n",
    "with open(path+'louvain_increaseK_highP.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'louvain_increaseK_highP.json','r') as fp:\n",
    "    data=json.load(fp)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment polarized graph according to Performances under Different Probability Distributions (RQ5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='datasets//l50_k2_p0.18_polarized_graph//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "       \n",
    "        k=[i for i in file_list if i[0]=='k'][0][1:]\n",
    "        l=[i for i in file_list if i[0]=='l'][0][1:]\n",
    "        name=file_list[-2]\n",
    "        \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=nx.community.louvain_communities(g)\n",
    "        \n",
    "        cluster=Trans_C2(cluster,int(k)*int(l))\n",
    "        cluster=Trans_C1(cluster)\n",
    "        \n",
    "        \n",
    "        louvain.update({name:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l50_k2_p0.18_polarized_graph//result//weigted_louvain//'\n",
    "with open(path+'louvain_polarized.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# real datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_core & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='mcp_acp_data//krogan2006_core//intersec_mips//net//krogan2006_core_mips_net.txt'\n",
    "\n",
    "\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "g=load_graph.read_g(path2)\n",
    "print(sorted(g.nodes))\n",
    "print(len(g.nodes))\n",
    "cluster=nx.community.louvain_communities(g)\n",
    "k=len(cluster)\n",
    "print(len(g.nodes))\n",
    "cluster=Trans_C2(cluster,len(g.nodes))\n",
    "cluster=Trans_C1(cluster)\n",
    "louvain.update({k:cluster})\n",
    "\n",
    "print(louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//krogan2006_core//intersec_mips//louvain_results//'\n",
    "with open(path+'louvain.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# krogan2006_extended & mips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='mcp_acp_data//krogan2006_extended//intersec_mips//net//krogan2006_extented_mips_net.txt'\n",
    "\n",
    "\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "g=load_graph.read_g(path2)\n",
    "print(sorted(g.nodes))\n",
    "print(len(g.nodes),len(g.edges))\n",
    "cluster=nx.community.louvain_communities(g)\n",
    "k=len(cluster)\n",
    "print(len(g.nodes))\n",
    "cluster=Trans_C2(cluster,len(g.nodes))\n",
    "cluster=Trans_C1(cluster)\n",
    "louvain.update({k:cluster})\n",
    "\n",
    "print(louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//krogan2006_extended//intersec_mips//louvain_results//'\n",
    "with open(path+'louvain.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Shifting Probabilities (RQ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Expected_mod import Trans_C1, APWP, Trans_C2\n",
    "import pKwikCluster as pkwik \n",
    "import Expected_mod as ex \n",
    "import load_graph\n",
    "import importlib\n",
    "import time\n",
    "import networkx as nx \n",
    "import pandas as pd \n",
    "import json\n",
    "import bz2\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "from os import listdir\n",
    "import networkx as nx\n",
    "\n",
    "path2='mcp_acp_data//l10_k10_p0.4_multiplied//new//datasets//'\n",
    "filelists=[i for i in os.listdir(path2)]\n",
    "filelists=Tcl().call('lsort','-dict',filelists)\n",
    "print(filelists)\n",
    "l=10\n",
    "k=10\n",
    "T=[]\n",
    "clustering=[]\n",
    "value=[]\n",
    "louvain={}\n",
    "\n",
    "for file in filelists:\n",
    "    if file[-4:] =='.txt':\n",
    "        file_list=file.split('_')\n",
    "        strr=[]\n",
    "        flag=0\n",
    "    \n",
    "        for _ in file:\n",
    "            \n",
    "            if _=='i':\n",
    "                \n",
    "                flag=1\n",
    "                \n",
    "                continue\n",
    "            if flag==0:\n",
    "                continue\n",
    "           \n",
    "\n",
    "            if _<'0' or _>'9' :\n",
    "            \n",
    "                break\n",
    "            strr.append(_)\n",
    "    \n",
    "        multi=str(0)+'.'+str(strr[1])#sum([int(strr[i])*(10**(len(strr)-(i+1))) for i in range(len(strr))])\n",
    "        print('m',multi)\n",
    "            \n",
    "       \n",
    "        g=load_graph.read_g(path2+file)\n",
    "        \n",
    " \n",
    "        # repeat three times\n",
    "    \n",
    "      \n",
    "       \n",
    "        \n",
    "        cluster=nx.community.louvain_communities(g)\n",
    "        \n",
    "        cluster=Trans_C2(cluster,int(k)*int(l))\n",
    "        cluster=Trans_C1(cluster)\n",
    "        \n",
    "        \n",
    "        louvain.update({multi:cluster})\n",
    "        \n",
    "\n",
    "        print('----------graph: ',file,'----------')\n",
    "        print('cluster:',cluster)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path='mcp_acp_data//l10_k10_p0.4_multiplied//new//louvain_results//'\n",
    "with open(path+'louvain.json','w') as fp:\n",
    "          json.dump(louvain,fp,indent=4) # With indent=4 (pretty format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
